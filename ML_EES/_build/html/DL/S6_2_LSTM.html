

<!DOCTYPE html>


<html >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>7.3. Q6) Convert the prepared datasets into PyTorch Datasets &#8212; Machine Learning for Earth and Environmental Sciences</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "light";
  </script>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="../_static/styles/theme.css?digest=e353d410970836974a52" rel="stylesheet" />
<link href="../_static/styles/bootstrap.css?digest=e353d410970836974a52" rel="stylesheet" />
<link href="../_static/styles/pydata-sphinx-theme.css?digest=e353d410970836974a52" rel="stylesheet" />

  
  <link href="../_static/vendor/fontawesome/6.1.2/css/all.min.css?digest=e353d410970836974a52" rel="stylesheet" />
  <link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.1.2/webfonts/fa-solid-900.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.1.2/webfonts/fa-brands-400.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.1.2/webfonts/fa-regular-400.woff2" />

    <link rel="stylesheet" type="text/css" href="../_static/pygments.css" />
    <link rel="stylesheet" href="../_static/styles/sphinx-book-theme.css?digest=14f4ca6b54d191a8c7657f6c759bf11a5fb86285" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/mystnb.4510f1fc1dee50b3e5859aac5469c37c29e427902b24a333a5f9fcb2f0b3ac41.css" />
    <link rel="stylesheet" type="text/css" href="../_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="../_static/design-style.4045f2051d55cab465a707391d5b2007.min.css" />
  
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../_static/scripts/bootstrap.js?digest=e353d410970836974a52" />
<link rel="preload" as="script" href="../_static/scripts/pydata-sphinx-theme.js?digest=e353d410970836974a52" />

    <script data-url_root="../" id="documentation_options" src="../_static/documentation_options.js"></script>
    <script src="../_static/jquery.js"></script>
    <script src="../_static/underscore.js"></script>
    <script src="../_static/doctools.js"></script>
    <script src="../_static/clipboard.min.js"></script>
    <script src="../_static/copybutton.js"></script>
    <script src="../_static/scripts/sphinx-book-theme.js?digest=5a5c038af52cf7bc1a1ec88eea08e6366ee68824"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="../_static/togglebutton.js"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script src="../_static/design-tabs.js"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"
const thebe_selector = ".thebe,.cell"
const thebe_selector_input = "pre"
const thebe_selector_output = ".output, .cell_output"
</script>
    <script async="async" src="../_static/sphinx-thebe.js"></script>
    <script>window.MathJax = {"options": {"processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script>DOCUMENTATION_OPTIONS.pagename = 'DL/S6_2_LSTM';</script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="prev" title="7.2. Exercise 1: Comparing Different Types of Recurrent and Convolutional Neural Networks to Compose Bach Chorales" href="S6_1_Composing_Music_With_RNNs_CNNs.html" />
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="None"/>
  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <a class="skip-link" href="#main-content">Skip to main content</a>
  
  <input type="checkbox"
          class="sidebar-toggle"
          name="__primary"
          id="__primary"/>
  <label class="overlay overlay-primary" for="__primary"></label>
  
  <input type="checkbox"
          class="sidebar-toggle"
          name="__secondary"
          id="__secondary"/>
  <label class="overlay overlay-secondary" for="__secondary"></label>
  
  <div class="search-button__wrapper">
    <div class="search-button__overlay"></div>
    <div class="search-button__search-container">
<form class="bd-search d-flex align-items-center"
      action="../search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         id="search-input"
         placeholder="Search this book..."
         aria-label="Search this book..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form></div>
  </div>
  
    <nav class="bd-header navbar navbar-expand-lg bd-navbar">
    </nav>
  
  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      <div class="bd-sidebar-primary bd-sidebar">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
    
    
  </div>
  
    <div class="sidebar-primary-items__start sidebar-primary__section">
        <div class="sidebar-primary-item">
  

<a class="navbar-brand logo" href="../index.html">
  
  
  
  
    
    
      
    
    
    <img src="../_static/logo.png" class="logo__image only-light" alt="Logo image"/>
    <script>document.write(`<img src="../_static/logo.png" class="logo__image only-dark" alt="Logo image"/>`);</script>
  
  
</a></div>
        <div class="sidebar-primary-item"><nav class="bd-links" id="bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item navbar-nav active">
        
        <ul class="nav bd-sidenav bd-sidenav__home-link">
            <li class="toctree-l1">
                <a class="reference internal" href="../index.html">
                    Welcome to Machine Learning for Earth and Environmental Sciences
                </a>
            </li>
        </ul>
        <p aria-level="2" class="caption" role="heading"><span class="caption-text">Introduction</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../Milton/00_Running_Python_Scripts.html">Running Python scripts</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">(Part I) Basics of Scientific Programming for Applied Machine Learning</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1 has-children"><a class="reference internal" href="../IP/intro_python.html">1. Introduction to Python for Earth and Environmental Sciences</a><input class="toctree-checkbox" id="toctree-checkbox-1" name="toctree-checkbox-1" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-1"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../IP/W1_S1_Tutorial.html">1.1. Variables, Control Flow, and File I/O</a></li>
<li class="toctree-l2"><a class="reference internal" href="../IP/W1_S1.html">1.2. (Exercises) Text and Tabular Files</a></li>
<li class="toctree-l2"><a class="reference internal" href="../IP/W1_S2_Tutorial.html">1.3. Data Structure, Functions, and Classes</a></li>
<li class="toctree-l2"><a class="reference internal" href="../IP/W1_S2.html">1.4. (Exercises) Simple Data Structures</a></li>
<li class="toctree-l2"><a class="reference internal" href="../IP/W2_S1_Tutorial.html">1.5. Scientific Computing with Numpy</a></li>
<li class="toctree-l2"><a class="reference internal" href="../IP/W2_S1.html">1.6. (Exercise) Ocean Floats Data Analysis</a></li>
<li class="toctree-l2"><a class="reference internal" href="../IP/W2_S2_Tutorial.html">1.7. Visualization with Matplotlib and Cartopy</a></li>
<li class="toctree-l2"><a class="reference internal" href="../IP/W2_S2.html">1.8. (Exercises) Replicating plots</a></li>
<li class="toctree-l2"><a class="reference internal" href="../IP/W3_S1_Tutorial.html">1.9. Tabular Data with Pandas</a></li>
<li class="toctree-l2"><a class="reference internal" href="../IP/W3_S1.html">1.10. (Exercise) Earthquake Data Analysis</a></li>
<li class="toctree-l2"><a class="reference internal" href="../IP/W3_S2_Tutorial.html">1.11. Geospatial Data with Geopandas</a></li>
<li class="toctree-l2"><a class="reference internal" href="../IP/W3_S2.html">1.12. (Exercise) Hurricane Track Analysis</a></li>
<li class="toctree-l2"><a class="reference internal" href="../IP/W4_S1_Tutorial.html">1.13. Regression, Classification, and Clustering with Scikit-learn</a></li>
<li class="toctree-l2"><a class="reference internal" href="../IP/W4_S1.html">1.14. (Exercises) Multivariate linear regression and clustering</a></li>
<li class="toctree-l2"><a class="reference internal" href="../IP/W4_S2_Tutorial.html">1.15. Statistical Graphics with Seaborn</a></li>
<li class="toctree-l2"><a class="reference internal" href="../IP/W4_S2.html">1.16. (Exercise) Marathon Data Analysis</a></li>
</ul>
</li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">(Part II) Basics of Machine Learning for Earth and Environmental Sciences</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1 has-children"><a class="reference internal" href="../ML/Week_1_Linear%26Logistic_Regression.html">2. Linear Regression for Regression, Logistic Regression for Classification and Statistical Forecasting</a><input class="toctree-checkbox" id="toctree-checkbox-2" name="toctree-checkbox-2" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-2"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../Saranya/W1_2.html">2.1. Classification and Regression</a></li>
<li class="toctree-l2"><a class="reference internal" href="../ML/S1_1_Classification.html">2.2. (Exercises) Classification</a></li>
<li class="toctree-l2"><a class="reference internal" href="../ML/S1_2_Training_Models.html">2.3. (Exercises) Training Models</a></li>
<li class="toctree-l2"><a class="reference internal" href="../Saranya/W1_2_Stat.html">2.4. Statistical Forecasting in Environmental Sciences</a></li>
<li class="toctree-l2"><a class="reference internal" href="../ML/S1_3_Statistical_Forecasting.html">2.5. (Exercises) Statistical Forecasting</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../ML/Week_2_Decision_Trees_Random_Forests_SVMs.html">3. Decision Trees, Random Forests, Support Vector Machines and Environmental Risk Analysis</a><input class="toctree-checkbox" id="toctree-checkbox-3" name="toctree-checkbox-3" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-3"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../Frederick/Simple_Machine_Learning_Algorithms_for_Classification_Tasks.html">3.1. Simple Machine Learning Algorithms for Classification Tasks</a></li>
<li class="toctree-l2"><a class="reference internal" href="../Frederick/%28Exercises%29_Support_Vector_Machines.html">3.2. (Exercises) Support Vector Machines</a></li>
<li class="toctree-l2"><a class="reference internal" href="../Frederick/%28Exercises%29_Decision_Trees_and_Random_Forest.html">3.3. (Exercises) Decision Trees and Random Forest</a></li>
<li class="toctree-l2"><a class="reference internal" href="../Frederick/%28Exercises%29_Ensemble_Modeling_and_Stacking.html">3.4. Ensemble Modeling and Stacking</a></li>
<li class="toctree-l2"><a class="reference internal" href="../Frederick/%28Exercises%29_Wildfire_Susceptibility_Mapping.html">3.5. (Exercises) Wildfire Susceptibility Mapping</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../ML/Week_3_Dimensionality_Reduction_Clustering.html">4. Unsupervised Learning for Clustering/Dimensionality Reduction and Environmental Complexity</a><input class="toctree-checkbox" id="toctree-checkbox-4" name="toctree-checkbox-4" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-4"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../Jingyan/Chapter4-UnsupervisedLearning.html">4.1. Unsupervised Learning for Clustering and Dimensionality Reduction</a></li>
<li class="toctree-l2"><a class="reference internal" href="../ML/S3_1_Dimensionality.html">4.2. (Exercise) Dimensionality Reduction</a></li>
<li class="toctree-l2"><a class="reference internal" href="../ML/S3_2_Clustering.html">4.3. (Exercise) Clustering</a></li>
<li class="toctree-l2"><a class="reference internal" href="../ML/S3_3_THOR.html">4.4. (Exercise) Ocean Regimes Identification</a></li>
</ul>
</li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">(Part III) Deep Learning for the Geosciences</span></p>
<ul class="current nav bd-sidenav">
<li class="toctree-l1 has-children"><a class="reference internal" href="Week_4_Artificial_Neural_Networks.html">5. Artificial Neural Networks and Surrogate Modeling</a><input class="toctree-checkbox" id="toctree-checkbox-5" name="toctree-checkbox-5" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-5"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="S4_1_NNs_with_Keras.html">5.1. (Exercise) Artificial Neural Networks with Keras</a></li>
<li class="toctree-l2"><a class="reference internal" href="S4_2_Physically_informed_parameterization.html">5.2. (Exercise) Physically-Informed Climate Modeling</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="Week_5_Convolutional_NN.html">6. Convolutional Neural Networks and Remote Sensing</a><input class="toctree-checkbox" id="toctree-checkbox-6" name="toctree-checkbox-6" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-6"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../Jingyan/Ch5%20Convolutional%20Neural%20Networks%20%26%20Remote%20Sensing.html">6.1. Convolutional Neural Networks and Remote Sensing</a></li>
<li class="toctree-l2"><a class="reference internal" href="S5_1_CNNs.html">6.2. (Exercise) Deep Computer Vision</a></li>
<li class="toctree-l2"><a class="reference internal" href="S5_2_CNN_and_EuroSAT.html">6.3. (Exercise) Land Cover Classification</a></li>
</ul>
</li>
<li class="toctree-l1 current active has-children"><a class="reference internal" href="Week_6_Recurrent_NN.html">7. Recurrent Neural Networks and Hydrological Modeling</a><input checked="" class="toctree-checkbox" id="toctree-checkbox-7" name="toctree-checkbox-7" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-7"><i class="fa-solid fa-chevron-down"></i></label><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="../Frederick/Neural_Networks_for_Time_Series_Predictions.html">7.1. Neural Networks for Time Series Predictions</a></li>
<li class="toctree-l2"><a class="reference internal" href="S6_1_Composing_Music_With_RNNs_CNNs.html">7.2. (Exercise) Composing Music</a></li>
<li class="toctree-l2 current active"><a class="current reference internal" href="#">7.3. <strong>Q6) Convert the prepared datasets into PyTorch Datasets</strong></a></li>






</ul>
</li>
</ul>

    </div>
</nav></div>
    </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
  </div>
  
  <div id="rtd-footer-container"></div>


      </div>
      
      <main id="main-content" class="bd-main">
        
        

<div class="sbt-scroll-pixel-helper"></div>

          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item"><label class="sidebar-toggle primary-toggle btn btn-sm" for="__primary" title="Toggle primary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
  <span class="fa-solid fa-bars"></span>
</label></div>
      
    </div>
  
  
    <div class="header-article-items__end">
      
        <div class="header-article-item">

<div class="article-header-buttons">





<div class="dropdown dropdown-source-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Source repositories">
    <i class="fab fa-github"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="https://github.com/executablebooks/jupyter-book" target="_blank"
   class="btn btn-sm btn-source-repository-button dropdown-item"
   title="Source repository"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fab fa-github"></i>
  </span>
<span class="btn__text-container">Repository</span>
</a>
</li>
      
      
      
      
      <li><a href="https://github.com/executablebooks/jupyter-book/issues/new?title=Issue%20on%20page%20%2FDL/S6_2_LSTM.html&body=Your%20issue%20content%20here." target="_blank"
   class="btn btn-sm btn-source-issues-button dropdown-item"
   title="Open an issue"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-lightbulb"></i>
  </span>
<span class="btn__text-container">Open issue</span>
</a>
</li>
      
  </ul>
</div>






<div class="dropdown dropdown-download-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Download this page">
    <i class="fas fa-download"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="../_sources/DL/S6_2_LSTM.ipynb" target="_blank"
   class="btn btn-sm btn-download-source-button dropdown-item"
   title="Download source file"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="btn__text-container">.ipynb</span>
</a>
</li>
      
      
      
      
      <li>
<button onclick="window.print()"
  class="btn btn-sm btn-download-pdf-button dropdown-item"
  title="Print to PDF"
  data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="btn__text-container">.pdf</span>
</button>
</li>
      
  </ul>
</div>




<button onclick="toggleFullScreen()"
  class="btn btn-sm btn-fullscreen-button"
  title="Fullscreen mode"
  data-bs-placement="bottom" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>


<script>
document.write(`
  <button class="theme-switch-button btn btn-sm btn-outline-primary navbar-btn rounded-circle" title="light/dark" aria-label="light/dark" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="theme-switch" data-mode="light"><i class="fa-solid fa-sun"></i></span>
    <span class="theme-switch" data-mode="dark"><i class="fa-solid fa-moon"></i></span>
    <span class="theme-switch" data-mode="auto"><i class="fa-solid fa-circle-half-stroke"></i></span>
  </button>
`);
</script>

<script>
document.write(`
  <button class="btn btn-sm navbar-btn search-button search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass"></i>
  </button>
`);
</script>
<label class="sidebar-toggle secondary-toggle btn btn-sm" for="__secondary"title="Toggle secondary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="fa-solid fa-list"></span>
</label>
</div></div>
      
    </div>
  
</div>
</div>
              
              

<div id="jb-print-docs-body" class="onlyprint">
    <h1>Q6) Convert the prepared datasets into PyTorch Datasets</h1>
    <!-- Table of contents -->
    <div id="print-main-content">
        <div id="jb-print-toc">
            
            <div>
                <h2> Contents </h2>
            </div>
            <nav aria-label="Page">
                <ul class="visible nav section-nav flex-column">
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#">7.3. <strong>Q6) Convert the prepared datasets into PyTorch Datasets</strong></a></li>
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#q7-define-the-hyperparameters-and-settings-for-training">7.4. <strong>Q7) Define the hyperparameters and settings for training</strong></a></li>
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#q8-define-the-training-validation-and-test-dataloaders">7.5. <strong>Q8) Define the training, validation, and test Dataloaders</strong></a></li>
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#q9-define-the-lstm-model-architecture">7.6. <strong>Q9) Define the LSTM model architecture</strong></a></li>
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#q10-define-the-loss-function-instantiate-the-model-define-the-optimizer-and-set-the-number-of-epochs-to-iterate-through">7.7. <strong>Q10) Define the loss function, instantiate the model, define the optimizer, and set the number of epochs to iterate through</strong></a></li>
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#q11-define-the-model-evaluation-function">7.8. <strong>Q11) Define the model evaluation function</strong></a></li>
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#q12-write-the-training-loop">7.9. <strong>Q12) Write the training loop</strong></a></li>
</ul>

            </nav>
        </div>
    </div>
</div>

              
                
<div id="searchbox"></div>
                <article class="bd-article" role="main">
                  
  <p><a href="https://colab.research.google.com/github/tbeucler/2022_ML_EES/blob/main/Labs/S6_2_LSTM.ipynb" target="_parent"><img src="https://colab.research.google.com/assets/colab-badge.svg" alt="Open In Colab"/></a></p>
<p>#<strong>Week 6 Exercise 2 – Recurrent Neural Networks for Hydrological Modeling</strong></p>
<center><img src='https://unils-my.sharepoint.com/:i:/g/personal/tom_beucler_unil_ch/EX7p8EcOwelFg3UkF7576noBzjdubEy10lWXbULT_N6QHw?download=1' width=100%> <i>The rain fell alike upon the just and upon the unjust, and for nothing was there a why and a wherefore. - William Somerset Maugham</i> </center>
<br>
<p>Rain is oft described as having a gloomy beauty to it, and it continues to inspire authors and scientists alike. Can we use machine learning algorithms to predict rainfall runoff with comparable accuracies to other established methods?</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1">#@title  Run this cell for preliminary requirements. Double click it if you want to check out the source :)</span>

<span class="c1"># Python ≥3.5 is required</span>
<span class="kn">import</span> <span class="nn">sys</span>
<span class="k">assert</span> <span class="n">sys</span><span class="o">.</span><span class="n">version_info</span> <span class="o">&gt;=</span> <span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">5</span><span class="p">)</span>

<span class="c1"># Is this notebook running on Colab or Kaggle?</span>
<span class="n">IS_COLAB</span> <span class="o">=</span> <span class="s2">&quot;google.colab&quot;</span> <span class="ow">in</span> <span class="n">sys</span><span class="o">.</span><span class="n">modules</span>

<span class="c1"># Scikit-Learn ≥0.20 is required</span>
<span class="kn">import</span> <span class="nn">sklearn</span>
<span class="k">assert</span> <span class="n">sklearn</span><span class="o">.</span><span class="n">__version__</span> <span class="o">&gt;=</span> <span class="s2">&quot;0.20&quot;</span>

<span class="c1"># Common imports</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="kn">import</span> <span class="nn">os</span>

<span class="c1"># To make this notebook&#39;s output stable across runs</span>
<span class="n">rnd_seed</span> <span class="o">=</span> <span class="mi">42</span>
<span class="n">rnd_gen</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">default_rng</span><span class="p">(</span><span class="n">rnd_seed</span><span class="p">)</span>

<span class="c1"># To plot pretty figures</span>
<span class="o">%</span><span class="k">matplotlib</span> inline
<span class="kn">import</span> <span class="nn">matplotlib</span> <span class="k">as</span> <span class="nn">mpl</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="n">mpl</span><span class="o">.</span><span class="n">rc</span><span class="p">(</span><span class="s1">&#39;axes&#39;</span><span class="p">,</span> <span class="n">labelsize</span><span class="o">=</span><span class="mi">14</span><span class="p">)</span>
<span class="n">mpl</span><span class="o">.</span><span class="n">rc</span><span class="p">(</span><span class="s1">&#39;xtick&#39;</span><span class="p">,</span> <span class="n">labelsize</span><span class="o">=</span><span class="mi">12</span><span class="p">)</span>
<span class="n">mpl</span><span class="o">.</span><span class="n">rc</span><span class="p">(</span><span class="s1">&#39;ytick&#39;</span><span class="p">,</span> <span class="n">labelsize</span><span class="o">=</span><span class="mi">12</span><span class="p">)</span>

<span class="c1"># Where to save the figures</span>
<span class="n">PROJECT_ROOT_DIR</span> <span class="o">=</span> <span class="s2">&quot;.&quot;</span>
<span class="n">CHAPTER_ID</span> <span class="o">=</span> <span class="s2">&quot;classification&quot;</span>
<span class="n">IMAGES_PATH</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">PROJECT_ROOT_DIR</span><span class="p">,</span> <span class="s2">&quot;images&quot;</span><span class="p">,</span> <span class="n">CHAPTER_ID</span><span class="p">)</span>
<span class="n">os</span><span class="o">.</span><span class="n">makedirs</span><span class="p">(</span><span class="n">IMAGES_PATH</span><span class="p">,</span> <span class="n">exist_ok</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

<span class="k">def</span> <span class="nf">save_fig</span><span class="p">(</span><span class="n">fig_id</span><span class="p">,</span> <span class="n">tight_layout</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">fig_extension</span><span class="o">=</span><span class="s2">&quot;png&quot;</span><span class="p">,</span> <span class="n">resolution</span><span class="o">=</span><span class="mi">300</span><span class="p">):</span>
    <span class="n">path</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">IMAGES_PATH</span><span class="p">,</span> <span class="n">fig_id</span> <span class="o">+</span> <span class="s2">&quot;.&quot;</span> <span class="o">+</span> <span class="n">fig_extension</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Saving figure&quot;</span><span class="p">,</span> <span class="n">fig_id</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">tight_layout</span><span class="p">:</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">tight_layout</span><span class="p">()</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">savefig</span><span class="p">(</span><span class="n">path</span><span class="p">,</span> <span class="nb">format</span><span class="o">=</span><span class="n">fig_extension</span><span class="p">,</span> <span class="n">dpi</span><span class="o">=</span><span class="n">resolution</span><span class="p">)</span>

<span class="c1"># Import pooch - used to handle data downloading</span>
<span class="kn">import</span> <span class="nn">pooch</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output traceback highlight-ipythontb notranslate"><div class="highlight"><pre><span></span><span class="gt">---------------------------------------------------------------------------</span>
<span class="ne">ModuleNotFoundError</span><span class="g g-Whitespace">                       </span>Traceback (most recent call last)
<span class="n">Cell</span> <span class="n">In</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">line</span> <span class="mi">11</span>
<span class="g g-Whitespace">      </span><span class="mi">8</span> <span class="n">IS_COLAB</span> <span class="o">=</span> <span class="s2">&quot;google.colab&quot;</span> <span class="ow">in</span> <span class="n">sys</span><span class="o">.</span><span class="n">modules</span>
<span class="g g-Whitespace">     </span><span class="mi">10</span> <span class="c1"># Scikit-Learn ≥0.20 is required</span>
<span class="ne">---&gt; </span><span class="mi">11</span> <span class="kn">import</span> <span class="nn">sklearn</span>
<span class="g g-Whitespace">     </span><span class="mi">12</span> <span class="k">assert</span> <span class="n">sklearn</span><span class="o">.</span><span class="n">__version__</span> <span class="o">&gt;=</span> <span class="s2">&quot;0.20&quot;</span>
<span class="g g-Whitespace">     </span><span class="mi">14</span> <span class="c1"># Common imports</span>

<span class="ne">ModuleNotFoundError</span>: No module named &#39;sklearn&#39;
</pre></div>
</div>
</div>
</div>
<p>Welcome to the practical application notebook for this week, where we’ll be using a Long-Short Term Memory (LSTM) neural network in order to model rainfall-runoff! Let’s begin by loading in our data using pooch and pandas.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1">#@title Let&#39;s download the data onto the storage on the server using pooch. Remember you can check the source by double cliking on cells like these. </span>
<span class="n">data_url</span> <span class="o">=</span> <span class="s1">&#39;https://unils-my.sharepoint.com/:x:/g/personal/tom_beucler_unil_ch/EQ0OKNafmxdJvXUMPfwGyecBwCPZJ1Y8_ATlmbrUFySkzw?download=1&#39;</span>
<span class="n">data_file</span> <span class="o">=</span> <span class="n">pooch</span><span class="o">.</span><span class="n">retrieve</span><span class="p">(</span><span class="n">data_url</span><span class="p">,</span> <span class="n">known_hash</span><span class="o">=</span><span class="s1">&#39;3b647bb9318865be5858bccd1539148fbc58f7425d09ac62d8e459682958940a&#39;</span><span class="p">);</span>
</pre></div>
</div>
</div>
</div>
<p>###<strong>Q1) Go ahead and load the csv file with the data for our project today. The filepath is stored in the <code class="docutils literal notranslate"><span class="pre">data_file</span></code> variable that was defined in the hidden code within the cell above this one!</strong></p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1">#@title Hints - Loading CSVs with Pandas</span>

<span class="sd">&#39;&#39;&#39;</span>
<span class="sd">Pandas has a handy .read_csv function!</span>

<span class="sd">There&#39;s an argument you can pass which will let you define the column to use as</span>
<span class="sd">an index. </span>

<span class="sd">There&#39;s also a single argument which when set to true will make pandas try to</span>
<span class="sd">automatically parse fields it thinks are dates into datetime variables. This</span>
<span class="sd">will be usefull when we split the data!</span>

<span class="sd">&#39;&#39;&#39;</span><span class="p">;</span>
<span class="c1"># Uncomment the line below and run this cell to open up the help dialog in colab</span>
<span class="c1">#pd.read_csv??</span>

<span class="c1"># Uncomment the code below and run the cell to get a look at the data </span>
<span class="c1">#pd.read_csv(data_file).head()</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Let&#39;s load the CSV file into the &quot;data&quot; variable</span>
<span class="n">data</span> <span class="o">=</span> <span class="n">_______</span><span class="o">.</span><span class="n">_______</span><span class="p">(</span><span class="n">_______</span><span class="p">,</span> <span class="c1"># Path to the CSV</span>
                       <span class="n">_______</span> <span class="o">=</span> <span class="n">_______</span><span class="p">,</span> <span class="c1"># Define the date column as the index. </span>
                       <span class="n">_______</span> <span class="o">=</span> <span class="n">_______</span><span class="p">,</span> <span class="c1"># Tell pandas to parse the date index.</span>
                       <span class="p">)</span>

<span class="c1"># Print the first 5 rows of data to see if we&#39;ve loaded it correctly! </span>
<span class="n">data</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
<p>We now have our data in a nice format for us to use. You’ll see that our data has an index column, a T column, a P1 column, a P2 column, and a runoff column. The index column is the date of our measurements, the T column is the mean daily temperature at a station, the P1 and P2 columns are the daily precipitations at two stations, and the runoff column is the daily streamflow at one station.</p>
<p>Let’s go ahead and figure out how many years of data we have by looking at the time index.</p>
<p>###<strong>Q2) Store the list of available years of data in a variable, and print out the length of the list.</strong></p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1">#@title Hint: How to use Pandas datetimeIndex</span>
<span class="sd">&#39;&#39;&#39;</span>
<span class="sd">When loading the data, we used the date column as the index - this means that </span>
<span class="sd">we can access the date using the .index attribute of the dataframe.</span>
<span class="sd">e.g.: for the df dataframe, df.index will return the index column</span>

<span class="sd">Additionally, we set parse_dates to True, so the dates were transformed from</span>
<span class="sd">a simple test representation of the date to a more powerfull pandas datetime</span>
<span class="sd">format. Here, we can directly access key parts of the date</span>
<span class="sd">e.g.: df.index.month will retrieve the month for each row index.</span>

<span class="sd">This can be useful for verifying or selected seasonal data, such as</span>
<span class="sd">for winter (december-january-february, or djf). Using built-in pandas functions</span>
<span class="sd">to find the unique values in the index.month column would let us</span>
<span class="sd">verify that all relevant month values are present (i.e., 1, 2, 12)</span>
<span class="sd">&#39;&#39;&#39;</span><span class="p">;</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">years_available</span> <span class="o">=</span> <span class="n">_______</span><span class="o">.</span><span class="n">_______</span><span class="o">.</span><span class="n">_______</span><span class="o">.</span><span class="n">_______</span><span class="p">()</span> <span class="c1"># Find the unique year values</span>
<span class="nb">print</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">years_available</span><span class="p">))</span>
</pre></div>
</div>
</div>
</div>
<p>Now we need to split the dataset into a training, validation, and test set to use with our algorithm. Since we’re dealing with time series data, let’s use the last 10 of the years available as the test dataset, the 10 years previous to that as the validation dataset, and the remainder of the data will be used to train our algorithm.</p>
<p>###<strong>Q3) Split the dataset into a training, validation, and test set.</strong></p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1">#@title Hint: Review of array slicing</span>
<span class="sd">&#39;&#39;&#39;</span>
<span class="sd">You can select data in an array/DataFrame using an index within square brackets</span>
<span class="sd">data[num_index] will return the value of data at the nth num_index entry. This</span>
<span class="sd">also works with negative numbers, which are used to count from the end of the </span>
<span class="sd">array.</span>
<span class="sd">e.g., if we define myArray = [0 1 2 3 4 5 6 7 8 9]</span>
<span class="sd">myArray[0] will return 0, myArray[1] will return 1</span>
<span class="sd">myArray[-1] will return 9, myArray[-2] will return 8</span>

<span class="sd">We can also select multiple values of the array using colons. Remember that</span>
<span class="sd">indices use the [start:end:step] convention</span>
<span class="sd">myArray [4:] will return [4, 5, 6, 7, 8, 9]</span>
<span class="sd">myArray [:4] will return [0, 1, 2, 3]</span>
<span class="sd">myArray [2:5] will return [2,3,4]</span>
<span class="sd">myArray [-3:] will return [7, 8, 9]</span>
<span class="sd">myArray [-5:-2] will return [5, 6, 7]</span>
<span class="sd">myArray [2:-2] will return [2, 3, 4, 5, 6, 7]</span>

<span class="sd">Stepping</span>
<span class="sd">myArray [::2] will return [0, 2, 4, 6, 8]</span>
<span class="sd">myArray [-4::2] will return [6, 8]</span>
<span class="sd">myArray [2:-2:2] will return [2, 4, 6]</span>
<span class="sd">&#39;&#39;&#39;</span><span class="p">;</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1">#@title Hint: Finding/Selecting data in a Pandas dataframe</span>
<span class="sd">&#39;&#39;&#39;</span>
<span class="sd">Pandas dataframes have useful functions that allow you to filter values.</span>
<span class="sd">One way to filter for specific time values is to rely on the `isin()` method</span>
<span class="sd">of datasets. https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.isin.html</span>

<span class="sd">For example, if we were trying to take a dataset covering every month of the</span>
<span class="sd">year and we&#39;re only interested in the winter season (DJF), we could use:</span>
<span class="sd">boolean_index = df.index.month.isin([12,1,2])</span>
<span class="sd">This would return a boolean index that you can use to select the relevant rows</span>
<span class="sd">from the dataframe.</span>

<span class="sd">In order to select the relevant datapoints, you can rely on the .loc method: </span>
<span class="sd">https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.loc.html</span>
<span class="sd">Using this method, you could select the data as follows:</span>
<span class="sd">relevant_datapoints = df.loc[boolean_index]</span>

<span class="sd">If you want to select every month that is _not_ in winter, you would instead</span>
<span class="sd">write: </span>
<span class="sd">relevant_datapoints = df.loc[~boolean_index]</span>
<span class="sd">Since ~ is the bitwise negation operator, it effectively &quot;nots&quot; boolean arrays</span>
<span class="sd">&#39;&#39;&#39;</span><span class="p">;</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1">#Select the last ten years for your test set</span>
<span class="n">test_years</span> <span class="o">=</span> <span class="n">years_available</span><span class="p">[</span><span class="n">_______</span><span class="p">:]</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Select ten years at random from the remaining set</span>
<span class="n">validation_years</span> <span class="o">=</span> <span class="n">years_available</span><span class="p">[</span><span class="n">_______</span><span class="p">:</span><span class="n">_______</span><span class="p">]</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># define the test set: test_set</span>
<span class="n">_______</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">_______</span><span class="p">[</span><span class="n">data</span><span class="o">.</span><span class="n">_______</span><span class="o">.</span><span class="n">_______</span><span class="o">.</span><span class="n">_______</span><span class="p">(</span><span class="n">test_years</span><span class="p">)]</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># define the validation set: val_set</span>
<span class="n">_______</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">_______</span><span class="p">[</span><span class="n">data</span><span class="o">.</span><span class="n">_______</span><span class="o">.</span><span class="n">_______</span><span class="o">.</span><span class="n">_______</span><span class="p">(</span><span class="n">validation_years</span><span class="p">)]</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># define the training set: train_set</span>
<span class="c1"># Note that the &#39;~&#39; translates to &quot;not&quot; - this allows us to find the training </span>
<span class="c1"># years by specifying it&#39;s those not in the list of test_years and validation_years</span>
<span class="n">_______</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">_______</span><span class="p">[</span><span class="o">~</span><span class="n">data</span><span class="o">.</span><span class="n">_______</span><span class="o">.</span><span class="n">_______</span><span class="o">.</span><span class="p">([</span><span class="o">*</span><span class="n">test_years</span><span class="p">,</span><span class="o">*</span><span class="n">validation_years</span><span class="p">])]</span>
</pre></div>
</div>
</div>
</div>
<p>The data we’re using today has already been cleaned up - we know it doesn’t have any NaN values.</p>
<p>Still, it’s good practire to check! Do so in the cell below.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Since booleans are interpreted as 0 or 1 when doing math, we can use the</span>
<span class="c1"># isna() method in pandas dataframes and sum the result to check how many NaN</span>
<span class="c1"># values are in the dataset. We should get 0 today!</span>
<span class="n">test_set</span><span class="o">.</span><span class="n">isna</span><span class="p">()</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Print out the first five rows of each dataset.</span>
<span class="c1"># Make sure that your split matches ours!</span>
<span class="nb">print</span><span class="p">(</span><span class="n">train_set</span><span class="o">.</span><span class="n">head</span><span class="p">(),</span> <span class="n">val_set</span><span class="o">.</span><span class="n">head</span><span class="p">(),</span> <span class="n">test_set</span><span class="o">.</span><span class="n">head</span><span class="p">(),</span> <span class="n">sep</span><span class="o">=</span><span class="s1">&#39;</span><span class="se">\n\n</span><span class="s1">&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>You should now have your dataset split up as three pandas dataframes. If you print out the first five rows of each dataset, you should get the following:</p>
<center><img src='https://unils-my.sharepoint.com/:i:/g/personal/tom_beucler_unil_ch/EUmui9FDDxxFpxjrY4I7MMABit-4pVJziPGmCZqMMwU28w?download=1'></center><p>We now have our data for training, validating, and testing our algorithm! However, the values are still the original ones from our measurements. We saw before that we generally want to transform these into stardardized values, otherwise we might end up with a <em>problem of scales.</em></p>
<center> <img src='https://unils-my.sharepoint.com/:i:/g/personal/tom_beucler_unil_ch/EQEslPIi1XZCgYGqSst2AOsBbZ5NHo7tpj1bFpW8Krzqgg?download=1' width=75%><br><font size=5><i>get it?</i></font></center>
<p>With that joke out of our system, let’s go ahead and prepare a Scikit-Learn pipeline to scale our data.</p>
<p>###<strong>Q4) Scale the input data using a StandardScaler (i.e., using the mean and standard deviation).</strong></p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1">#@title Hint: Review of Scikit Learn pipelines and transformers</span>
<span class="sd">&#39;&#39;&#39;</span>
<span class="sd">Scikit include several tools to preprocess data, ranging from utilities for</span>
<span class="sd">imputation to utilities for scaling data.</span>

<span class="sd">The column transformer will allow us to apply specific transformers to columns</span>
<span class="sd">in the pandas dataframe. We also can specify what to do with the </span>
<span class="sd">columns to which we don&#39;t want to apply transformations. You can check the</span>
<span class="sd">documentation at the link below:</span>
<span class="sd">https://scikit-learn.org/stable/modules/generated/sklearn.compose.ColumnTransformer.html</span>

<span class="sd">For example, take a dataframe including the temperature T, sea level pressure</span>
<span class="sd">SST, relative humidity RH, mean sea level pressure MSLP, and surface pressure SP</span>

<span class="sd">We want to train a model that takes T, SST, RH, and MSLP to make a weather </span>
<span class="sd">prediction, and want the variables to be scaled to fit strictly between 0 and 1.</span>
<span class="sd">Rather than code a script for this, a Column Transformer can be defined that</span>
<span class="sd">uses remained=&#39;drop&#39; as a parameter (thereby dropping SP), and a MinMaxScaler </span>
<span class="sd">function for the transformer.</span>

<span class="sd">The code would look something like:</span>
<span class="sd">preprocesser = ColumnTransformer(</span>
<span class="sd">                           remainder=&#39;drop&#39;, </span>
<span class="sd">                           transformers=[</span>
<span class="sd">                              (&#39;scaling&#39;, MinMaxScaler(), (&#39;T&#39;, &#39;SST&#39;, &#39;RH&#39;, &#39;MSLP&#39;)),</span>
<span class="sd">                           ])</span>

<span class="sd">The column transformer serves two functions: fitting and transforming</span>
<span class="sd">When fitting, the transformer takes the input data and figures out how it will</span>
<span class="sd">transform data later. In the example above, this would include calculating the</span>
<span class="sd">minimum and maximum value for each column.</span>

<span class="sd">Transforming takes the fitted transformer and calculates the new values of the</span>
<span class="sd">column, as well as performing any other operations on the data (e.g., dropping</span>
<span class="sd">the SP variable).</span>

<span class="sd">Generally, you want to fit the transformer using the training data, and then</span>
<span class="sd">transform the training data, the validation data, and the test data. We avoid</span>
<span class="sd">fitting to the validation and test data.</span>

<span class="sd">Additionally, though transformer.fit() and transformer.transform() exist</span>
<span class="sd">individually, fitting to and transforming the training data is so common that</span>
<span class="sd">a combined method is implemented in sklearn: fit_transform()</span>

<span class="sd">Today, you should use the StandardScaler in order to process your numerical</span>
<span class="sd">data. You can find more infomation about StandardScaler in the </span>
<span class="sd">&#39;&#39;&#39;</span><span class="p">;</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Import the parts of Scikit Learn we need for scaling</span>
<span class="kn">from</span> <span class="nn">sklearn.compose</span> <span class="kn">import</span> <span class="n">_______</span>
<span class="kn">from</span> <span class="nn">sklearn.preprocessing</span> <span class="kn">import</span> <span class="n">_______</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Create a Column Transformer</span>
<span class="n">scaler</span> <span class="o">=</span> <span class="n">_______</span><span class="p">(</span>
                           <span class="n">_______</span><span class="o">=</span><span class="s1">&#39;_______&#39;</span><span class="p">,</span> <span class="c1"># We leave the non-input columns alone</span>
                           <span class="n">_______</span><span class="o">=</span><span class="p">[</span>
                              <span class="p">(</span><span class="s1">&#39;_______&#39;</span><span class="p">,</span> <span class="n">_______</span><span class="p">,</span> <span class="p">(</span><span class="n">_______</span><span class="p">,</span> <span class="n">_______</span><span class="p">,</span> <span class="n">_______</span><span class="p">)),</span>
                           <span class="p">])</span> <span class="c1">#Define the scaler to use and which columns to use it on</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">train</span> <span class="o">=</span> <span class="n">_______</span><span class="o">.</span><span class="n">_______</span><span class="p">(</span><span class="n">_______</span><span class="p">)</span> <span class="c1"># fit the scaler and transform the train_set</span>
<span class="n">val</span> <span class="o">=</span> <span class="n">_______</span><span class="o">.</span><span class="n">_______</span><span class="p">(</span><span class="n">_______</span><span class="p">)</span> <span class="c1"># transform the val_set</span>
<span class="n">test</span> <span class="o">=</span> <span class="n">_______</span><span class="o">.</span><span class="n">_______</span><span class="p">(</span><span class="n">_______</span><span class="p">)</span> <span class="c1"># transform the test_set</span>
</pre></div>
</div>
</div>
</div>
<p>If you did everything right, the first two rows of your dataset should return:</p>
<p>Training: <br />
<code class="docutils literal notranslate"><span class="pre">[[-0.67248997</span> <span class="pre">-0.24609328</span> <span class="pre">-0.32674546</span>&#160; <span class="pre">3.91</span>&#160;&#160;&#160;&#160;&#160; <span class="pre">]</span></code><br />
<code class="docutils literal notranslate"> <span class="pre">[-0.67248997</span> <span class="pre">-0.07489897</span>&#160; <span class="pre">0.08869363</span>&#160; <span class="pre">4.01</span>&#160;&#160;&#160;&#160;&#160; <span class="pre">]]</span></code></p>
<p>Validation: <br />
<code class="docutils literal notranslate"><span class="pre">[[-1.28097285</span> <span class="pre">-0.47435235</span> <span class="pre">-0.47511657</span>&#160; <span class="pre">3.22</span>&#160;&#160;&#160;&#160;&#160; <span class="pre">]</span></code><br />
<code class="docutils literal notranslate"><span class="pre">[-1.06462338</span> <span class="pre">-0.10343136</span> <span class="pre">-0.03000326</span>&#160; <span class="pre">3.12</span>&#160;&#160;&#160;&#160;&#160; <span class="pre">]]</span></code></p>
<p>Test:<br />
<code class="docutils literal notranslate"><span class="pre">[[-1.02405785</span>&#160; <span class="pre">0.38161917</span>&#160; <span class="pre">0.6228296</span>&#160;&#160; <span class="pre">3.6</span>&#160;&#160;&#160;&#160;&#160;&#160; <span class="pre">]</span></code><br />
<code class="docutils literal notranslate"><span class="pre">[-1.1051889</span>&#160; <span class="pre">-0.44581996</span> <span class="pre">-0.47511657</span>&#160; <span class="pre">3.4</span>&#160;&#160;&#160;&#160;&#160;&#160; <span class="pre">]]</span></code></p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Make sure your datasets have been scaled correctly</span>
<span class="nb">print</span><span class="p">(</span><span class="n">train</span><span class="p">[:</span><span class="mi">2</span><span class="p">],</span> <span class="n">val</span><span class="p">[:</span><span class="mi">2</span><span class="p">],</span><span class="n">test</span><span class="p">[:</span><span class="mi">2</span><span class="p">],</span> <span class="n">sep</span><span class="o">=</span><span class="s1">&#39;</span><span class="se">\n\n</span><span class="s1">&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>We’re almost ready to start training our algorithm! However, we currently have a list of temperature, precipitation, and runoff readings <em>for each day</em> in our datasets. However, we’re interested in looking at an <span class="math notranslate nohighlight">\(n\)</span>-sized <strong>window</strong> of temperature and precipitation readings to predict a point in the runoff series!</p>
<p>As an example with <span class="math notranslate nohighlight">\( n= 5\)</span>: <span class="math notranslate nohighlight">\(\;\)</span>
to predict the runoff on a given Friday, we need the temperature and precipitation readings for Monday, Tuesday, Wednesday, Thursday, and the Friday itself.</p>
<p>###<strong>Q5) Turn the training, validation, and test data into a set of series to feed into an LSTM</strong></p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Let&#39;s start by printing out the shape of our training dataset</span>
<span class="nb">print</span><span class="p">(</span><span class="n">train</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Sequence length will determine how many days we will take into consideration</span>
<span class="c1"># when trying to predict the runoff. You can try multiple values, and we </span>
<span class="c1"># recommend you check out the results for n= [7, 30, 182, 365]</span>
<span class="n">sequence_length</span> <span class="o">=</span> <span class="n">_______</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># In order to get the windows for the input data, we&#39;ll rely on numpy&#39;s </span>
<span class="c1"># sliding window view. You can check the documentation for</span>
<span class="c1"># numpy.lib.stride_tricks.sliding_window_view for more information</span>
<span class="c1"># https://numpy.org/devdocs/reference/generated/numpy.lib.stride_tricks.sliding_window_view.html</span>

<span class="n">window_size</span> <span class="o">=</span> <span class="n">_______</span>


<span class="c1"># For the source array, since we&#39;re saving X, we just need the columns for T,</span>
<span class="c1"># P1, and P2. We don&#39;t want to include the runoff!</span>
<span class="n">train_X</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">lib</span><span class="o">.</span><span class="n">stride_tricks</span><span class="o">.</span><span class="n">sliding_window_view</span><span class="p">(</span><span class="n">_______</span><span class="p">[:,:</span><span class="n">_______</span><span class="p">],</span> <span class="c1"># source array</span>
                                                   <span class="n">_______</span><span class="p">,</span> <span class="c1"># window size </span>
                                                   <span class="n">_______</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span> <span class="c1"># Window Sliding Direction</span>

<span class="n">val_X</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">lib</span><span class="o">.</span><span class="n">stride_tricks</span><span class="o">.</span><span class="n">sliding_window_view</span><span class="p">(</span><span class="n">_______</span><span class="p">[:,:</span><span class="n">_______</span><span class="p">],</span> <span class="c1"># source array</span>
                                                 <span class="n">_______</span><span class="p">,</span> <span class="c1"># window size </span>
                                                 <span class="n">_______</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span> <span class="c1"># Window Sliding Direction</span>

<span class="n">test_X</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">lib</span><span class="o">.</span><span class="n">stride_tricks</span><span class="o">.</span><span class="n">sliding_window_view</span><span class="p">(</span><span class="n">_______</span><span class="p">[:,:</span><span class="n">_______</span><span class="p">],</span> <span class="c1"># source array</span>
                                                  <span class="n">_______</span><span class="p">,</span> <span class="c1"># window size </span>
                                                  <span class="n">_______</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span> <span class="c1"># Window Sliding Direction</span>
</pre></div>
</div>
</div>
</div>
<p>Let’s try printing out the shape of a transformed dataset…</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="n">train_X</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>You should find that the dataset has the wrong shape for our purposes! The sliding_window_view function will have returned the data in the shape:<br />
(number of samples, <strong>number_of_features</strong>, sequence_length)</p>
<p>However, the convention we’ve followed so far in our course (which is quite common in the field) is features last: <br />
(number of samples, sequence_length, <strong>number_of_features</strong>).</p>
<p>We can fix this with <code class="docutils literal notranslate"><span class="pre">numpy.moveaxis()</span></code>!</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">train_X</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">moveaxis</span><span class="p">(</span><span class="n">_______</span><span class="p">,</span> <span class="c1"># source array</span>
                      <span class="n">_______</span><span class="p">,</span> <span class="c1"># axis to move </span>
                      <span class="n">_______</span><span class="p">)</span> <span class="c1"># destination for the axis</span>

<span class="n">val_X</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">moveaxis</span><span class="p">(</span><span class="n">_______</span><span class="p">,</span> <span class="c1"># source array</span>
                    <span class="n">_______</span><span class="p">,</span> <span class="c1"># axis to move </span>
                    <span class="n">_______</span><span class="p">)</span> <span class="c1"># destination for the axis</span>

<span class="n">test_X</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">moveaxis</span><span class="p">(</span><span class="n">_______</span><span class="p">,</span> <span class="c1"># source array</span>
                     <span class="n">_______</span><span class="p">,</span> <span class="c1"># axis to move </span>
                     <span class="n">_______</span><span class="p">)</span> <span class="c1"># destination for the axis</span>
</pre></div>
</div>
</div>
</div>
<p>We now need to prepare the target data using the runoff column! <br />
Here, we just need to select the column, skipping over the first (<span class="math notranslate nohighlight">\(window\_size - 1\)</span>) elements.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># For each set, take the data between the window_size-1th element and the last element</span>
<span class="n">train_y</span> <span class="o">=</span> <span class="n">train</span><span class="p">[</span><span class="n">_______</span><span class="p">:,</span><span class="n">_______</span><span class="p">]</span>  
<span class="n">val_y</span> <span class="o">=</span> <span class="n">val</span><span class="p">[</span><span class="n">_______</span><span class="p">:,</span><span class="n">_______</span><span class="p">]</span>
<span class="n">test_y</span> <span class="o">=</span> <span class="n">test</span><span class="p">[</span><span class="n">_______</span><span class="p">:,</span><span class="n">_______</span><span class="p">]</span>
</pre></div>
</div>
</div>
</div>
<p>Let’s check the shape of our arrays to make sure that things make sense!</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;Train Shape:      X:</span><span class="si">{</span><span class="n">train_X</span><span class="o">.</span><span class="n">shape</span><span class="si">}</span><span class="s1">, y:</span><span class="si">{</span><span class="n">train_y</span><span class="o">.</span><span class="n">shape</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">,</span>
      <span class="sa">f</span><span class="s1">&#39;Validation Shape: X:</span><span class="si">{</span><span class="n">val_X</span><span class="o">.</span><span class="n">shape</span><span class="si">}</span><span class="s1">, y:</span><span class="si">{</span><span class="n">val_y</span><span class="o">.</span><span class="n">shape</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">,</span>
      <span class="sa">f</span><span class="s1">&#39;Test Shape:       X:</span><span class="si">{</span><span class="n">test_X</span><span class="o">.</span><span class="n">shape</span><span class="si">}</span><span class="s1">, y:</span><span class="si">{</span><span class="n">test_y</span><span class="o">.</span><span class="n">shape</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">,</span> <span class="n">sep</span><span class="o">=</span><span class="s1">&#39;</span><span class="se">\n</span><span class="s1">&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>During development, a window size of 365 days was used. With this window size, the shape of our input/output datasets are: <br />
<code class="docutils literal notranslate"><span class="pre">Train</span> <span class="pre">Shape:</span>&#160;&#160;&#160;&#160;&#160; <span class="pre">X:(6941,</span> <span class="pre">365,</span> <span class="pre">3),</span> <span class="pre">y:(6941,)</span></code> <br />
<code class="docutils literal notranslate"><span class="pre">Validation</span> <span class="pre">Shape:</span> <span class="pre">X:(3289,</span> <span class="pre">365,</span> <span class="pre">3),</span> <span class="pre">y:(3289,)</span></code> <br />
<code class="docutils literal notranslate"><span class="pre">Test</span> <span class="pre">Shape:</span>&#160;&#160;&#160;&#160;&#160;&#160; <span class="pre">X:(3288,</span> <span class="pre">365,</span> <span class="pre">3),</span> <span class="pre">y:(3288,)</span></code></p>
<p>We finally have a dataset that we can easily use to train an LSTM! From this point on, we’ll be relying on <a class="reference external" href="https://pytorch.org/">PyTorch</a> to get our model ready.</p>
<p>Let’s start by importing the parts that we’ll need. We won’t hide any of the code here so you can see everything that’s being done <em>without</em> extra clicking. \</p>
<center><font size=30>😀</font></center><div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Let&#39;s import the main PyTorch library</span>
<span class="kn">import</span> <span class="nn">torch</span>

<span class="c1"># Let&#39;s import the pytorch nn module, which gives us access to a simpler API for </span>
<span class="c1"># defining our model  (It includes layer abstractions and other nifty tools)</span>
<span class="kn">import</span> <span class="nn">torch.nn</span> <span class="k">as</span> <span class="nn">nn</span>

<span class="c1"># And import utilities to help us easily handle batch sizing</span>
<span class="kn">from</span> <span class="nn">torch.utils.data</span> <span class="kn">import</span> <span class="n">DataLoader</span><span class="p">,</span> <span class="n">TensorDataset</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1">#@title Run this cell to check if a GPU is available. We&#39;ll use a variable called `calc_device` to store either the cpu or gpu to run calculations on. </span>
<span class="k">if</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">device_count</span><span class="p">()</span><span class="o">&gt;</span><span class="mi">0</span><span class="p">:</span>
  <span class="n">calc_device</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">(</span><span class="s1">&#39;cuda:0&#39;</span><span class="p">)</span>
<span class="k">else</span><span class="p">:</span>
  <span class="n">calc_device</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">(</span><span class="s1">&#39;cpu&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>First, let’s start by moving away from Pandas Dataframes and NumPy N-Dimensional Arrays and into the realm of PyTorch <em>Tensors</em>.</p>
<div class="section" id="q6-convert-the-prepared-datasets-into-pytorch-datasets">
<h1><span class="section-number">7.3. </span><strong>Q6) Convert the prepared datasets into PyTorch Datasets</strong><a class="headerlink" href="#q6-convert-the-prepared-datasets-into-pytorch-datasets" title="Permalink to this headline">#</a></h1>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1">#@title Hint: Transitioning from Numpy ND-Arrays to Pytorch Tensors</span>
<span class="sd">&#39;&#39;&#39;</span>
<span class="sd">Pytorch includes utilities to change from numpy arrays to tensors. These include</span>
<span class="sd">torch.from_numpy(DATA_SOURCE) and torch.FloatTensor(DATA_SOURCE). We recommend</span>
<span class="sd">that you use FloatTensor, as its the default precision in PyTorch at the time of</span>
<span class="sd">writing. </span>

<span class="sd">Using from_numpy will default to double precision using our scripts so</span>
<span class="sd">far, and will raise an exception later unless you change everything to double</span>
<span class="sd">precision.</span>

<span class="sd">the .to() method sends the tensor to a device. Importantly, all tensors</span>
<span class="sd">should be on the same device. (Trying to do things across devices is very fancy</span>
<span class="sd">and is therefore outside the scope of the course!)</span>
<span class="sd">&#39;&#39;&#39;</span><span class="p">;</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1">#@title Hint: Datasets from Tensors</span>
<span class="sd">&#39;&#39;&#39;</span>
<span class="sd">You can make a dataset by calling </span>
<span class="sd">torch.TensorDataset(input_tensor, output_tensor)</span>

<span class="sd">This creates an subscriptable iterator (i.e., you can use an [index] to access </span>
<span class="sd">the index-th pair of input-output data)</span>

<span class="sd">Using this abstraction ensures that your input and output tensors have the same</span>
<span class="sd">size! It&#39;s a good sanity check.</span>
<span class="sd">&#39;&#39;&#39;</span><span class="p">;</span>
<span class="c1">#TensorDataset?</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Let&#39;s convert our numpy arrays into tensors</span>
<span class="n">train_Xtensor</span> <span class="o">=</span> <span class="n">_______</span><span class="o">.</span><span class="n">_______</span><span class="p">(</span><span class="n">_______</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">calc_device</span><span class="p">)</span>
<span class="n">train_ytensor</span> <span class="o">=</span> <span class="n">_______</span><span class="o">.</span><span class="n">_______</span><span class="p">(</span><span class="n">_______</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">calc_device</span><span class="p">)</span>

<span class="n">val_Xtensor</span> <span class="o">=</span> <span class="n">_______</span><span class="o">.</span><span class="n">_______</span><span class="p">(</span><span class="n">_______</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">calc_device</span><span class="p">)</span>
<span class="n">val_ytensor</span> <span class="o">=</span> <span class="n">_______</span><span class="o">.</span><span class="n">_______</span><span class="p">(</span><span class="n">_______</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">calc_device</span><span class="p">)</span>

<span class="n">test_Xtensor</span> <span class="o">=</span> <span class="n">_______</span><span class="o">.</span><span class="n">_______</span><span class="p">(</span><span class="n">_______</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">calc_device</span><span class="p">)</span>
<span class="n">test_ytensor</span> <span class="o">=</span> <span class="n">_______</span><span class="o">.</span><span class="n">_______</span><span class="p">(</span><span class="n">_______</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">calc_device</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># And group them into a dataset using the TensorDataset utility</span>
<span class="n">train_data</span> <span class="o">=</span> <span class="n">_______</span><span class="p">(</span><span class="n">_______</span><span class="p">,</span> <span class="n">_______</span><span class="p">)</span>
<span class="n">val_data</span> <span class="o">=</span> <span class="n">_______</span><span class="p">(</span><span class="n">_______</span><span class="p">,</span> <span class="n">_______</span><span class="p">)</span>
<span class="n">test_data</span> <span class="o">=</span> <span class="n">_______</span><span class="p">(</span><span class="n">_______</span><span class="p">,</span> <span class="n">_______</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>Let’s check that your tensors and datasets have been converted properly. Run the code below and compare it to our results (remember, we used 365 days as the window_size and a batch size of 128 - if your hyperparameters are different your numbers will be different)</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;X tensor size (train): </span><span class="si">{</span><span class="n">train_Xtensor</span><span class="o">.</span><span class="n">size</span><span class="p">()</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">,</span>
      <span class="sa">f</span><span class="s1">&#39;X tensor size (val): </span><span class="si">{</span><span class="n">train_Xtensor</span><span class="o">.</span><span class="n">size</span><span class="p">()</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">,</span>
      <span class="sa">f</span><span class="s1">&#39;X tensor size (test): </span><span class="si">{</span><span class="n">train_Xtensor</span><span class="o">.</span><span class="n">size</span><span class="p">()</span><span class="si">}</span><span class="se">\n</span><span class="s1">&#39;</span><span class="p">,</span>
      <span class="sa">f</span><span class="s1">&#39;Train dataset size =: </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">train_data</span><span class="p">)</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">,</span>
      <span class="sa">f</span><span class="s1">&#39;Validation dataset size =: </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">val_data</span><span class="p">)</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">,</span>
      <span class="sa">f</span><span class="s1">&#39;Test dataset size =: </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">test_data</span><span class="p">)</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">,</span>
      <span class="n">sep</span><span class="o">=</span><span class="s1">&#39;</span><span class="se">\n</span><span class="s1">&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>During development, the output of the cell above was: <br />
<code class="docutils literal notranslate"><span class="pre">X</span> <span class="pre">tensor</span> <span class="pre">size</span> <span class="pre">(train):</span> <span class="pre">torch.Size([6941,</span> <span class="pre">365,</span> <span class="pre">3])</span></code> <br />
<code class="docutils literal notranslate"><span class="pre">X</span> <span class="pre">tensor</span> <span class="pre">size</span> <span class="pre">(val):</span> <span class="pre">torch.Size([6941,</span> <span class="pre">365,</span> <span class="pre">3])</span></code> <br />
<code class="docutils literal notranslate"><span class="pre">X</span> <span class="pre">tensor</span> <span class="pre">size</span> <span class="pre">(test):</span> <span class="pre">torch.Size([6941,</span> <span class="pre">365,</span> <span class="pre">3])</span></code> \</p>
<p><code class="docutils literal notranslate"><span class="pre">Train</span> <span class="pre">dataset</span> <span class="pre">size</span> <span class="pre">=:</span> <span class="pre">6941</span></code> <br />
<code class="docutils literal notranslate"><span class="pre">Validation</span> <span class="pre">dataset</span> <span class="pre">size</span> <span class="pre">=:</span> <span class="pre">3289</span></code> <br />
<code class="docutils literal notranslate"><span class="pre">Test</span> <span class="pre">dataset</span> <span class="pre">size</span> <span class="pre">=:</span> <span class="pre">3288</span></code> \</p>
<p>Now that we have our datasets as PyTorch tensors, we can go ahead and load them into a <span class="math notranslate nohighlight">\(\color{Green}{\textit{DataLoader}}\)</span>.</p>
<p>In PyTorch, DataLoaders are an abstraction that let’s you do many powerful things to a dataset, such as: getting samples, shuffling, and other operations that are outside of the scope of this lab / course.</p>
<p>Before we make the DataLoaders, we need to define some hyperparameters for our training. Specifically, we want to define the <strong>batch size</strong> (i.e., how many sample you train on at a time). We also need to define a setting: the number of workers we’ll use.</p>
<p>We recommend you use a batch size of 128, and two workers. We won’t go into details on how large a batch size to use, especially as there is ongoing research on the topic (e.g., <a class="reference external" href="https://arxiv.org/abs/1609.04836">in</a> <a class="reference external" href="https://arxiv.org/abs/2006.08517">these</a> <a class="reference external" href="https://arxiv.org/abs/1711.00489">papers</a>). However, too large a batch size tends to make it harder for ML algorithms to generalize. As for the number of workers, this is generally dictaded by how many cpu/gpu cores you have available.</p>
</div>
<div class="section" id="q7-define-the-hyperparameters-and-settings-for-training">
<h1><span class="section-number">7.4. </span><strong>Q7) Define the hyperparameters and settings for training</strong><a class="headerlink" href="#q7-define-the-hyperparameters-and-settings-for-training" title="Permalink to this headline">#</a></h1>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1">#Define the hyperparameters</span>
<span class="n">batch_size</span> <span class="o">=</span> <span class="n">_______</span>
<span class="n">num_workers</span> <span class="o">=</span> <span class="n">_______</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="q8-define-the-training-validation-and-test-dataloaders">
<h1><span class="section-number">7.5. </span><strong>Q8) Define the training, validation, and test Dataloaders</strong><a class="headerlink" href="#q8-define-the-training-validation-and-test-dataloaders" title="Permalink to this headline">#</a></h1>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1">#@title Hint: PyTorch DataLoaders</span>
<span class="sd">&#39;&#39;&#39;</span>
<span class="sd">PyTorch Dataloaders</span>
<span class="sd">Now that you have a pytorch dataset, you can feed it into a dataloader.</span>
<span class="sd">Dataloaders can handle shuffling (important during training! Not so much</span>
<span class="sd">for validation and testing...), and will automatically cut the data into</span>
<span class="sd">batches if the batch_size parameter is given.</span>

<span class="sd">Our data is small this time, so this isn&#39;t strictly necessary. But it&#39;s good</span>
<span class="sd">practice.</span>
<span class="sd">&#39;&#39;&#39;</span><span class="p">;</span>
<span class="c1">#DataLoader?</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">train_loader</span> <span class="o">=</span> <span class="n">_______</span><span class="p">(</span>
    <span class="n">_______</span><span class="o">=</span><span class="n">_______</span><span class="p">,</span> <span class="c1"># Define the dataset to use</span>
    <span class="n">_______</span> <span class="o">=</span> <span class="n">_______</span><span class="p">,</span> <span class="c1"># Set the batch size</span>
    <span class="n">_______</span> <span class="o">=</span> <span class="kc">True</span><span class="o">/</span><span class="kc">False</span> <span class="c1"># Define if shuffling is necessary for this loader</span>
<span class="p">)</span>

<span class="n">val_loader</span> <span class="o">=</span> <span class="n">_______</span><span class="p">(</span>
    <span class="n">_______</span><span class="o">=</span><span class="n">_______</span><span class="p">,</span> <span class="c1"># Define the dataset to use</span>
    <span class="n">_______</span> <span class="o">=</span> <span class="n">_______</span><span class="p">,</span> <span class="c1"># Set the batch size</span>
    <span class="n">_______</span> <span class="o">=</span> <span class="kc">True</span><span class="o">/</span><span class="kc">False</span> <span class="c1"># Define if shuffling is necessary for this loader</span>
<span class="p">)</span>

<span class="n">test_loader</span> <span class="o">=</span> <span class="n">_______</span><span class="p">(</span>
    <span class="n">_______</span><span class="o">=</span><span class="n">_______</span><span class="p">,</span> <span class="c1"># Define the dataset to use</span>
    <span class="n">_______</span> <span class="o">=</span> <span class="n">_______</span><span class="p">,</span> <span class="c1"># Set the batch size</span>
    <span class="n">_______</span> <span class="o">=</span> <span class="kc">True</span><span class="o">/</span><span class="kc">False</span> <span class="c1"># Define if shuffling is necessary for this loader</span>
<span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>We’re now fully ready on the data side - let’s go on to setting up the neural network.</p>
<p>When we were using Tensorflow, we defined a neural network by defining an instance of <code class="docutils literal notranslate"><span class="pre">tensorflow.keras.Model()</span></code>. Now that we’re using pytorch, we’ll instead <em>extend</em> the equivalent of the model class in PyTorch - the <code class="docutils literal notranslate"><span class="pre">nn.Module</span></code> class. You can read more about the class in the <a class="reference external" href="https://pytorch.org/docs/stable/generated/torch.nn.Module.html">documentation</a> online.</p>
<p>Whenever we want to design a model with an LSTM layer, we’ll need to define how many LSTM units we want to use (this will be the first hyperparameter for our simple LSTM model).</p>
<p>We’ll also be adding a dropout layer to our simple LSTM architecture. That is, there will be a fixed chance that the output of each LSTM unit will be zeroed during training - this will make our model more robust. Also, the probability of zeroing an output will be another hyperparameter.</p>
<p>Finally, the last state of the LSTM layer are going to be combined linearly into a prediction for the runoff at the end of the time series. The default notebook will use a simple linear combination (i.e., we won’t be using an activation function on the combination the way we often did before).</p>
</div>
<div class="section" id="q9-define-the-lstm-model-architecture">
<h1><span class="section-number">7.6. </span><strong>Q9) Define the LSTM model architecture</strong><a class="headerlink" href="#q9-define-the-lstm-model-architecture" title="Permalink to this headline">#</a></h1>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1">#@title PyTorch Hints</span>

<span class="sd">&quot;&quot;&quot;</span>
<span class="sd">You can uncomment each snippet below to bring up the help pane for each one of</span>
<span class="sd">the nn.Module, nn.LSTM, nn.Dropout, and nn.Linear objects.</span>
<span class="sd">&quot;&quot;&quot;</span><span class="p">;</span>

<span class="c1">#nn.Module?</span>
<span class="c1">#nn.LSTM?</span>
<span class="c1">#nn.Dropout?</span>
<span class="c1">#nn.Linear?</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># We&#39;ll start by defining a class extension:</span>

<span class="k">class</span> <span class="nc">MyLSTM</span><span class="p">(</span><span class="n">_______</span><span class="p">):</span> <span class="c1"># Define the class which we&#39;re extending using our MyLSTM class</span>
    <span class="c1"># Begin by defining the initialization function for our class</span>
    <span class="k">def</span> <span class="nf">_______</span><span class="p">(</span><span class="n">_______</span><span class="p">,</span> <span class="c1"># The first argument to the class in all methods is itself </span>
                <span class="n">_______</span><span class="p">,</span> <span class="c1"># Model Hyperparameter 1</span>
                <span class="n">_______</span><span class="p">):</span> <span class="c1"># ModelHyperparameter 2</span>
        
        <span class="c1">#To make sure our class initializes properly, we&#39;ll call its superclass</span>
        <span class="c1"># (i.e., the class it&#39;s based off of) and run its </span>
        <span class="nb">super</span><span class="p">(</span><span class="n">MyLSTM</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>

        <span class="c1"># Store the hyperparameters passed into the class during initialization</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_______</span> <span class="o">=</span> <span class="n">_______</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_______</span> <span class="o">=</span> <span class="n">_______</span>

        <span class="c1"># Define the LSTM layer</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">LSTM_layer</span> <span class="o">=</span> <span class="n">________</span><span class="o">.</span><span class="n">________</span><span class="p">(</span> <span class="c1"># Let&#39;s instantiate the pytorch LSTM module </span>
            <span class="n">________</span> <span class="o">=</span> <span class="n">________</span><span class="p">,</span> <span class="c1"># The number of features in the input series</span>
            <span class="n">________</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">________</span><span class="p">,</span> <span class="c1"># The number of LSTM cells per layer</span>
            <span class="n">________</span> <span class="o">=</span> <span class="n">________</span><span class="p">,</span> <span class="c1"># The number of LSTM Layers</span>
            <span class="n">________</span> <span class="o">=</span> <span class="n">________</span><span class="p">,</span> <span class="c1"># Enable the use of biases</span>
            <span class="n">batch_first</span> <span class="o">=</span> <span class="kc">True</span> <span class="c1"># Let the layer know the input shape is (batch_size, series_len, num_features) </span>
        <span class="p">)</span>

        <span class="c1"># Define the Dropout Layer</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">dropout_layer</span> <span class="o">=</span> <span class="n">________</span><span class="o">.</span><span class="n">________</span><span class="p">(</span> <span class="c1">#Instantiate the pytorch dropout layer</span>
            <span class="n">________</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">________</span> <span class="c1"># Set the dropout rate</span>
        <span class="p">)</span>

        <span class="c1"># Define the the output layer - we&#39;ll make a linear aggregation of the LSTM outputs </span>
        <span class="bp">self</span><span class="o">.</span><span class="n">out_layer</span> <span class="o">=</span> <span class="n">________</span><span class="o">.</span><span class="n">________</span><span class="p">(</span> <span class="c1">#Instantiate the pytorch linear layer</span>
            <span class="n">________</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">________</span> <span class="c1"># Number of inputs</span>
            <span class="n">________</span> <span class="o">=</span> <span class="n">________</span> <span class="c1"># Number of predictions per number of inputs</span>
        <span class="p">)</span>
        
    <span class="c1"># Define the forward pass</span>
    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">):</span>
        
        <span class="c1"># Calculate the LSTM output, hidden state, and memory cell</span>
        <span class="c1"># Note that output is not our model&#39;s output!</span>
        <span class="c1"># Read the documentation here: https://pytorch.org/docs/stable/generated/torch.nn.LSTM.html</span>
        <span class="n">output</span><span class="p">,</span> <span class="p">(</span><span class="n">h_n</span><span class="p">,</span> <span class="n">c_n</span><span class="p">)</span>  <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">LSTM_layer</span><span class="p">(</span><span class="n">_____</span><span class="p">)</span>
        
        <span class="c1"># Calculate our model&#39;s hidden state from the last hidden state of the LSTM</span>
        <span class="c1"># using our dropout layer</span>
        <span class="n">hidden_state</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_______</span><span class="p">(</span><span class="n">h_n</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>

        <span class="c1"># Make the prediction by using the relu( dense ( hidden_state ) )      </span>
        <span class="n">p_hat</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">flatten</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">_______</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_______</span><span class="p">(</span><span class="n">hidden_state</span><span class="p">)))</span>
        <span class="k">return</span> <span class="n">_______</span>
</pre></div>
</div>
</div>
</div>
<p>Now that we have the model defined, we’ll also be using a metric of performance that is somewhat more uncommon in machine learning applications than in hydrology - the <strong>Nash-Sutcliff-Efficiency (NSE) Coefficient</strong>. You can read more about it <a class="reference external" href="https://en.wikipedia.org/wiki/Nash%E2%80%93Sutcliffe_model_efficiency_coefficient">on Wikipedia</a>.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1">#@title Run this cell to define the NSE calculation function. It will be accessible as `calc_NSE`</span>

<span class="c1"># Customzied evaluation metric NSE for validation set and test set # </span>
<span class="k">def</span> <span class="nf">calc_nse</span><span class="p">(</span><span class="n">sim</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">FloatTensor</span><span class="p">,</span> <span class="n">obs</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">FloatTensor</span><span class="p">,</span> <span class="n">global_obs_mean</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">FloatTensor</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">float</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Calculate the Nash-Sutcliff-Efficiency coefficient.</span>

<span class="sd">    :param obs: Array containing the observations</span>
<span class="sd">    :param sim: Array containing the simulations</span>
<span class="sd">    :param global_obs_mean: mean of the whole observation series</span>
<span class="sd">    :return: NSE value.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">numerator</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">square</span><span class="p">(</span><span class="n">sim</span> <span class="o">-</span> <span class="n">obs</span><span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span>
    <span class="n">denominator</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">square</span><span class="p">(</span><span class="n">obs</span> <span class="o">-</span> <span class="n">global_obs_mean</span><span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span>
    <span class="n">nse_val</span> <span class="o">=</span> <span class="mi">1</span> <span class="o">-</span> <span class="n">numerator</span> <span class="o">/</span> <span class="n">denominator</span>

    <span class="k">return</span> <span class="n">nse_val</span>
</pre></div>
</div>
</div>
</div>
<p>The next thing we need to think about is the hyperparameters for our model and training. More specifically, we need to choose:</p>
<ul class="simple">
<li><p>a number of LSTM units</p></li>
<li><p>the dropout rate</p></li>
<li><p>define our loss function</p></li>
<li><p>choose our optimizer and its parameters.</p></li>
<li><p>define the number of epochs we will train for</p></li>
</ul>
<p>Thankfully, it’s not our first rodeo! \</p>
<center><font size=30>🤠</font></center>
<p>Regarding the number of units, we chose 16 units during development of the notebook. Feel free to change this, e.g. to values between 1 and 128.</p>
<p>The dropout rate is the probability that an LSTM unit will be zeroed. We’ll set it to 0.125 (i.e., 1/8), which means we expect to drop the output from ~two of the LSTM cells at random. You can read more <a class="reference external" href="https://pytorch.org/docs/stable/generated/torch.nn.Dropout.html">here</a>.</p>
<p>Since this is a regression problem, we’ll rely on MSE as the loss function.</p>
<p>We’ve also know that Adam is a reliable optimizer, so we’ll go ahead and use that. Adam needs us to define a learning rate, and <span class="math notranslate nohighlight">\(1*10^{-3}\)</span> is a common default value. We’ll try it out to see if it’s appropriate.</p>
<p>Note that you’re free to play around with these hyperparameters - your performance will just be different from the ones we will show if you do so. I’m sure you can find a better solution 😀</p>
</div>
<div class="section" id="q10-define-the-loss-function-instantiate-the-model-define-the-optimizer-and-set-the-number-of-epochs-to-iterate-through">
<h1><span class="section-number">7.7. </span><strong>Q10) Define the loss function, instantiate the model, define the optimizer, and set the number of epochs to iterate through</strong><a class="headerlink" href="#q10-define-the-loss-function-instantiate-the-model-define-the-optimizer-and-set-the-number-of-epochs-to-iterate-through" title="Permalink to this headline">#</a></h1>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Define the loss function for training </span>
<span class="n">loss_func</span> <span class="o">=</span> <span class="n">_______</span><span class="o">.</span><span class="n">_______</span><span class="p">()</span>

<span class="c1"># Instantiate our LSTM model</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">MyLSTM</span><span class="p">(</span><span class="n">_______</span><span class="o">=</span><span class="n">_______</span><span class="p">,</span> <span class="c1"># Hyperparameter 1</span>
               <span class="n">_______</span><span class="o">=</span><span class="n">_______</span><span class="p">,</span> <span class="c1"># Hyperparameter 2</span>
               <span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">calc_device</span><span class="p">)</span> <span class="c1"># Make sure the model is on the same device as the Tensors </span>

<span class="c1"># Define our optimizer</span>
<span class="n">optimizer</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">Adam</span><span class="p">(</span><span class="n">_______</span><span class="o">.</span><span class="n">_______</span><span class="p">(),</span> <span class="c1"># We need to pass the parameters the optimizer will optimize</span>
                             <span class="n">_______</span><span class="o">=</span><span class="n">_______</span><span class="p">)</span> <span class="c1"># and pass the learning rate for the optimizer</span>

<span class="c1"># Define the number of epochs</span>
<span class="n">num_epochs</span> <span class="o">=</span> <span class="n">_______</span>
</pre></div>
</div>
</div>
</div>
<p>We’re almost ready to train our model. Before we move on to the training routine, let’s take a minute to define how we will evaluate the performance of the model - both for validation during training and for testing after training!</p>
</div>
<div class="section" id="q11-define-the-model-evaluation-function">
<h1><span class="section-number">7.8. </span><strong>Q11) Define the model evaluation function</strong><a class="headerlink" href="#q11-define-the-model-evaluation-function" title="Permalink to this headline">#</a></h1>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">eval_model</span><span class="p">(</span><span class="n">_______</span><span class="p">,</span> <span class="c1"># the model to be evaluated</span>
               <span class="n">_______</span><span class="p">,</span> <span class="c1"># the dataloader for the dataset used for the evaluation</span>
               <span class="n">_______</span><span class="p">,</span> <span class="c1"># the main loss function to be used </span>
               <span class="n">_______</span><span class="p">):</span> <span class="c1"># the function to be used as a performance metric</span>
    <span class="c1"># Tell pytorch that we don&#39;t need to keep track of the gradients</span>
    <span class="c1"># After all, gradients are only used during training.</span>

    <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">_______</span><span class="p">():</span>       
        
        <span class="c1">#Zero the loss and the metric</span>
        <span class="n">_______</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="n">_______</span> <span class="o">=</span> <span class="mi">0</span>

        <span class="c1"># We&#39;ll start by calculating the mean of the whole dataset</span>
        <span class="c1"># This will be used in the NSE coefficient calculation</span>
        
        <span class="c1"># Start by defining a placeholder variable for the sum of the </span>
        <span class="c1"># observations, and another for the number of datapoints in the set</span>
        <span class="n">global_sum</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="n">label_size</span> <span class="o">=</span> <span class="mi">0</span>

        <span class="c1"># Iterate through the features and labels in the dataloader</span>
        <span class="k">for</span> <span class="n">_______</span><span class="p">,</span> <span class="n">_______</span> <span class="ow">in</span> <span class="n">_______</span><span class="p">:</span>
            <span class="c1"># add the sum of the labels to the global sum</span>
            <span class="n">global_sum</span> <span class="o">+=</span> <span class="n">_______</span><span class="o">.</span><span class="n">_______</span><span class="p">()</span>

            <span class="c1"># Keep track of how many labels we&#39;ve seen</span>
            <span class="n">label_size</span> <span class="o">+=</span> <span class="nb">len</span><span class="p">(</span><span class="n">_______</span><span class="p">)</span> 
        
        <span class="c1"># Calculate the mean of the observations using the information gathered</span>
        <span class="n">global_mean</span> <span class="o">=</span> <span class="n">_______</span><span class="o">/</span><span class="n">_______</span>

        <span class="c1"># Iterate through the features and labels in the dataloader, this time</span>
        <span class="c1"># for evaluating the model</span>
        <span class="k">for</span> <span class="n">_______</span><span class="p">,</span> <span class="n">_______</span> <span class="ow">in</span> <span class="n">_______</span><span class="p">:</span>
            <span class="c1"># get predictions from the model using the features in the batch</span>
            <span class="n">_______</span> <span class="o">=</span> <span class="n">_______</span><span class="p">(</span><span class="n">_______</span><span class="p">)</span>

            <span class="c1"># calculate the batch loss</span>
            <span class="n">batch_loss</span> <span class="o">=</span> <span class="n">_______</span><span class="p">(</span><span class="n">_______</span><span class="p">,</span> <span class="n">_______</span><span class="p">)</span>

            <span class="c1">#calculate the batch metric</span>
            <span class="n">batch_metric</span> <span class="o">=</span> <span class="n">_______</span><span class="p">(</span><span class="n">_______</span><span class="p">,</span> <span class="n">_______</span><span class="p">,</span> <span class="n">_______</span><span class="p">)</span>

            <span class="c1"># Keep track of the loss and metric. Remember to convert them from </span>
            <span class="c1"># pytorch tensors to scalars</span>
            <span class="n">loss</span> <span class="o">+=</span> <span class="n">_______</span><span class="o">.</span><span class="n">_______</span><span class="p">()</span>
            <span class="n">metric</span> <span class="o">+=</span> <span class="n">_______</span><span class="o">.</span><span class="n">_______</span><span class="p">()</span>
        
        <span class="c1"># Calculate the number of batches in the dataloader</span>
        <span class="n">num_batches</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">_______</span><span class="p">)</span>

        <span class="c1"># Calculate the mean loss</span>
        <span class="n">loss</span> <span class="o">=</span> <span class="n">loss</span><span class="o">/</span><span class="n">_______</span>
        <span class="n">metric</span> <span class="o">=</span> <span class="n">metric</span><span class="o">/</span><span class="n">_______</span>
        
        <span class="k">return</span> <span class="p">(</span><span class="n">loss</span><span class="p">,</span> <span class="n">metric</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>With PyTorch, unlike with Keras, we need to write out the training and evaluation routines! We’ll do this by using a nested for loops - the outer loop will run for the number of epochs, while the inner loops will iterate over the batches to train and validate the model.</p>
<p>The outer loop will do the following:</p>
<ul class="simple">
<li><p>Set the training loss to zero</p></li>
<li><p>Train the model</p></li>
<li><p>Get the validation loss and metrics using our evaluation function</p></li>
<li><p>Store the training and validation metrics</p></li>
</ul>
</div>
<div class="section" id="q12-write-the-training-loop">
<h1><span class="section-number">7.9. </span><strong>Q12) Write the training loop</strong><a class="headerlink" href="#q12-write-the-training-loop" title="Permalink to this headline">#</a></h1>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Define empty lists that will be used to keep track of the training losses,</span>
<span class="c1"># validation losses, and validation metrics  </span>
<span class="n">_______</span> <span class="o">=</span> <span class="n">_______</span>
<span class="n">_______</span> <span class="o">=</span> <span class="n">_______</span>
<span class="n">_______</span> <span class="o">=</span> <span class="n">_______</span>

<span class="c1">#</span>
<span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">_______</span><span class="p">):</span>
    <span class="c1"># Zero the training loss</span>
    <span class="n">_______</span> <span class="o">=</span> <span class="mi">0</span>

    <span class="c1"># Iterate through the features and labels in the train dataloader </span>
    <span class="k">for</span> <span class="n">_______</span><span class="p">,</span> <span class="n">_______</span> <span class="ow">in</span> <span class="n">_______</span><span class="p">:</span>
        <span class="c1"># We need to zero the gradients associated with the model parameters.</span>
        <span class="c1"># We can do this directly using the optimizer</span>
        <span class="n">_______</span><span class="o">.</span><span class="n">_______</span><span class="p">()</span>

        <span class="c1"># Get predictions from the features using the model</span>
        <span class="n">pred</span> <span class="o">=</span> <span class="n">_______</span><span class="p">(</span><span class="n">_______</span><span class="p">)</span>

        <span class="c1"># And use the predictions to calculate the batch loss</span>
        <span class="n">batch_loss</span> <span class="o">=</span> <span class="n">_______</span><span class="p">(</span><span class="n">_______</span><span class="p">,</span> <span class="n">_______</span><span class="p">)</span>

        <span class="c1"># Do the backprogragation from the batch_loss</span>
        <span class="n">_______</span><span class="o">.</span><span class="n">_______</span><span class="p">()</span>

        <span class="c1"># Step through the optimizer</span>
        <span class="n">_______</span><span class="o">.</span><span class="n">_______</span><span class="p">()</span>

        <span class="c1"># Keep track of the train loss sum. </span>
        <span class="c1"># Remember to turn the tensor into a scalar!</span>
        <span class="n">train_loss</span> <span class="o">+=</span> <span class="n">_______</span><span class="o">.</span><span class="n">_______</span><span class="p">()</span>

    <span class="c1"># Calculate the number of batches in the training dataloader</span>
    <span class="n">num_batches</span> <span class="o">=</span> <span class="n">_______</span><span class="p">(</span><span class="n">_______</span><span class="p">)</span>

    <span class="c1"># Get the mean training loss over the batches</span>
    <span class="n">train_loss</span> <span class="o">=</span> <span class="n">_______</span><span class="o">/</span><span class="n">_______</span>

    <span class="c1"># And append it into the list we defined to keep track of the loss</span>
    <span class="n">_______</span><span class="o">.</span><span class="n">_______</span><span class="p">(</span><span class="n">_______</span><span class="p">)</span>
    
    <span class="c1"># Calculate the validation loss and metric.</span>
    <span class="c1"># Use the function we defined before!</span>
    <span class="n">val_loss</span><span class="p">,</span> <span class="n">val_NSE</span> <span class="o">=</span> <span class="n">_______</span><span class="p">(</span><span class="n">_______</span><span class="p">,</span> <span class="c1"># The model</span>
                                <span class="n">_______</span><span class="p">,</span> <span class="c1"># The dataloader</span>
                                <span class="n">_______</span><span class="p">,</span> <span class="c1"># The loss function</span>
                                <span class="n">_______</span><span class="p">)</span> <span class="c1"># The metric function</span>

    <span class="c1"># Append the metric and loss values into the lists we made to keep track</span>
    <span class="n">val_losses</span><span class="o">.</span><span class="n">_______</span><span class="p">(</span><span class="n">_______</span><span class="p">)</span>
    <span class="n">val_NSEs</span><span class="o">.</span><span class="n">_______</span><span class="p">(</span><span class="n">_______</span><span class="p">)</span>

    <span class="c1"># We want to save the model if it&#39;s the best version of it we&#39;ve found</span>
    <span class="c1"># during training. If the NSE coefficient is the maximum in our training </span>
    <span class="c1"># history, we&#39;ll go ahead and save the model as our best model.</span>
    <span class="k">if</span> <span class="n">val_NSE</span> <span class="o">&gt;=</span> <span class="nb">max</span><span class="p">(</span><span class="n">val_NSEs</span><span class="p">):</span>
      <span class="n">torch</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="s1">&#39;./best_model.pt&#39;</span><span class="p">)</span>

    <span class="c1"># And print out a statement to keep track of our training as we iterate</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;</span><span class="se">\r</span><span class="s1">Epoch: </span><span class="si">{</span><span class="n">_______</span><span class="o">+</span><span class="mi">1</span><span class="si">}</span><span class="s1">/</span><span class="si">{</span><span class="n">_______</span><span class="si">}</span><span class="s1">,&#39;</span> <span class="c1"># Current epoch, total number of epochs</span>
          <span class="sa">f</span><span class="s1">&#39;train_loss: </span><span class="si">{</span><span class="n">_______</span><span class="si">}</span><span class="s1">,&#39;</span> <span class="c1"># training loss we found this epoch</span>
          <span class="sa">f</span><span class="s1">&#39;val_loss: </span><span class="si">{</span><span class="n">_______</span><span class="si">}</span><span class="s1">,&#39;</span> <span class="c1"># validation loss we found this epoch</span>
          <span class="sa">f</span><span class="s1">&#39;NSE: </span><span class="si">{</span><span class="n">_______</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">,</span> <span class="c1"># NSE coefficient we found this epoch</span>
          <span class="n">end</span><span class="o">=</span><span class="s2">&quot;&quot;</span><span class="p">)</span>
 
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1">#@title Run this cell to load the best model from our training before we evaluate the performance.</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">load</span><span class="p">(</span> <span class="s1">&#39;./best_model.pt&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Plotting out the Training and Validation performance. We&#39;ll use </span>
<span class="c1"># torch.no_grad() since we don&#39;t need to calculate the gradients for</span>
<span class="c1"># plotting</span>
<span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
    <span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="n">figsize</span> <span class="o">=</span> <span class="p">(</span><span class="mi">20</span><span class="p">,</span><span class="mi">5</span><span class="p">),</span> <span class="n">dpi</span><span class="o">=</span><span class="mi">150</span><span class="p">)</span>
    
    <span class="c1"># Plot the training losses</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">train_losses</span><span class="p">,</span>
            <span class="n">c</span><span class="o">=</span><span class="s1">&#39;black&#39;</span><span class="p">,</span> 
            <span class="n">linewidth</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
            <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Training Loss&#39;</span><span class="p">)</span>
    
    <span class="c1"># Plot the validation losses</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">val_losses</span><span class="p">,</span>
            <span class="n">c</span><span class="o">=</span><span class="s1">&#39;orange&#39;</span><span class="p">,</span> 
            <span class="n">linewidth</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
            <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Validation Loss&#39;</span><span class="p">)</span>
    
    <span class="c1"># Empty NSE plot, used for easy legend generation</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">plot</span><span class="p">([],</span>
            <span class="n">color</span><span class="o">=</span><span class="s1">&#39;teal&#39;</span><span class="p">,</span>
            <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Nash-Sutcliff-Efficiency&#39;</span><span class="p">)</span>
    
    <span class="c1"># Copy</span>
    <span class="n">metric_ax</span> <span class="o">=</span> <span class="n">ax</span><span class="o">.</span><span class="n">twinx</span><span class="p">()</span>
    <span class="n">metric_ax</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">val_NSEs</span><span class="p">,</span>
            <span class="n">c</span><span class="o">=</span><span class="s1">&#39;teal&#39;</span><span class="p">,</span> 
            <span class="n">linewidth</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
            <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Nash-Sutcliff-Efficiency&#39;</span><span class="p">)</span>
    <span class="n">metric_ax</span><span class="o">.</span><span class="n">set_ylim</span><span class="p">([</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">])</span>
    <span class="n">metric_ax</span><span class="o">.</span><span class="n">set_yticks</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span><span class="mf">1.01</span><span class="p">,</span><span class="mf">0.25</span><span class="p">))</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">autoscale</span><span class="p">(</span><span class="n">enable</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="s1">&#39;x&#39;</span><span class="p">,</span> <span class="n">tight</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">legend</span><span class="p">(</span><span class="n">loc</span><span class="o">=</span><span class="s1">&#39;center right&#39;</span><span class="p">)</span>
    <span class="n">fig</span><span class="o">.</span><span class="n">set_facecolor</span><span class="p">(</span><span class="s1">&#39;lightgrey&#39;</span><span class="p">)</span>  
</pre></div>
</div>
</div>
</div>
<p>If you did everything the exact same way we did during development of the notebook (i.e., you chose the same hyperparameters as us) you should<span class="math notranslate nohighlight">\(^*\)</span> get a set of training curves that look just like the ones below:</p>
<center><img src='https://unils-my.sharepoint.com/:i:/g/personal/tom_beucler_unil_ch/EV_Tbnodg1VEkMbDkk8eRYgBE0KAl9KgnIYLKxLtb0lTog?download=1' width=100%>
<p><span class="math notranslate nohighlight">\(_{^{*}\text{GPU calculations are often non-deterministic for performance reasons, so you should get something remarkably similar, though not quite the same}}\)</span></p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1">#Plotting out the Predicted Time Series on the Dataset</span>
<span class="n">test_obs_mean</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">test_ytensor</span><span class="p">)</span>
<span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
    <span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="n">figsize</span> <span class="o">=</span> <span class="p">(</span><span class="mi">20</span><span class="p">,</span><span class="mi">5</span><span class="p">),</span> <span class="n">dpi</span><span class="o">=</span><span class="mi">150</span><span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">test_set</span><span class="o">.</span><span class="n">index</span><span class="p">[</span><span class="n">window_size</span><span class="o">-</span><span class="mi">1</span><span class="p">:],</span> 
            <span class="n">test_ytensor</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">(),</span>
            <span class="n">c</span><span class="o">=</span><span class="s1">&#39;teal&#39;</span><span class="p">,</span> 
            <span class="n">linewidth</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
            <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Observed&#39;</span><span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">test_set</span><span class="o">.</span><span class="n">index</span><span class="p">[</span><span class="n">window_size</span><span class="o">-</span><span class="mi">1</span><span class="p">:],</span> 
            <span class="n">model</span><span class="p">(</span><span class="n">test_Xtensor</span><span class="p">)</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">(),</span> 
            <span class="n">c</span><span class="o">=</span><span class="s1">&#39;orange&#39;</span><span class="p">,</span> 
            <span class="n">alpha</span><span class="o">=</span><span class="mf">0.85</span><span class="p">,</span> 
            <span class="n">linewidth</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
            <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Predictions&#39;</span><span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">axhline</span><span class="p">(</span><span class="n">test_ytensor</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span><span class="o">.</span><span class="n">item</span><span class="p">(),</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;teal&#39;</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span> <span class="n">linestyle</span><span class="o">=</span><span class="s1">&#39;--&#39;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Observation Mean&#39;</span><span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
    <span class="n">mse</span><span class="p">,</span> <span class="n">NSE</span> <span class="o">=</span> <span class="n">eval_model</span><span class="p">(</span><span class="n">model</span><span class="p">,</span>
                          <span class="n">test_loader</span><span class="p">,</span>
                          <span class="n">loss_func</span><span class="p">,</span>
                          <span class="n">calc_nse</span><span class="p">)</span>
    <span class="n">fig</span><span class="o">.</span><span class="n">suptitle</span><span class="p">(</span><span class="s1">&#39;Performance on Test Dataset&#39;</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="mi">14</span><span class="p">)</span>
    <span class="n">fig</span><span class="o">.</span><span class="n">set_facecolor</span><span class="p">(</span><span class="s1">&#39;lightgrey&#39;</span><span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;MSE: </span><span class="si">{</span><span class="n">mse</span><span class="si">:</span><span class="s1">0.2f</span><span class="si">}</span><span class="s1">  Nash-Sutcliff-Efficiency: </span><span class="si">{</span><span class="n">NSE</span><span class="si">:</span><span class="s1">0.2f</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="mi">11</span><span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s1">&#39;Discharge ($</span><span class="se">\\</span><span class="s1">frac</span><span class="si">{mm}{day}</span><span class="s1">$)&#39;</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="mi">11</span><span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">autoscale</span><span class="p">(</span><span class="n">enable</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="s1">&#39;x&#39;</span><span class="p">,</span> <span class="n">tight</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>Finally, assuming your decisions and ours were the same, evaluating your model with the code above should<span class="math notranslate nohighlight">\(^*\)</span> give you the figure below:</p>
<center><img src='https://unils-my.sharepoint.com/:i:/g/personal/tom_beucler_unil_ch/EUEtOgx5IzBJjIFELU3KdvIBDpFB1d_qnNr_HarNvVMGYA?download=1' width=100%>
<p><span class="math notranslate nohighlight">\(_{^{*}\text{Once again, GPU operations are generally non-deterministic - you should get something remarkably similar}}\)</span></p>
</div>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            name: "python3",
            path: "./DL"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

                </article>
              

              
              
                <footer class="bd-footer-article">
                  
<div class="footer-article-items footer-article__inner">
  
    <div class="footer-article-item"><!-- Previous / next buttons -->
<div class="prev-next-area">
    <a class="left-prev"
       href="S6_1_Composing_Music_With_RNNs_CNNs.html"
       title="previous page">
      <i class="fa-solid fa-angle-left"></i>
      <div class="prev-next-info">
        <p class="prev-next-subtitle">previous</p>
        <p class="prev-next-title"><span class="section-number">7.2. </span>Exercise 1: Comparing Different Types of Recurrent and Convolutional Neural Networks to Compose Bach Chorales</p>
      </div>
    </a>
</div></div>
  
</div>

                </footer>
              
            </div>
            
            
              
                <div class="bd-sidebar-secondary bd-toc"><div class="sidebar-secondary-items sidebar-secondary__inner">

  <div class="sidebar-secondary-item">
  <div class="page-toc tocsection onthispage">
    <i class="fa-solid fa-list"></i> Contents
  </div>
  <nav class="bd-toc-nav page-toc">
    <ul class="visible nav section-nav flex-column">
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#">7.3. <strong>Q6) Convert the prepared datasets into PyTorch Datasets</strong></a></li>
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#q7-define-the-hyperparameters-and-settings-for-training">7.4. <strong>Q7) Define the hyperparameters and settings for training</strong></a></li>
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#q8-define-the-training-validation-and-test-dataloaders">7.5. <strong>Q8) Define the training, validation, and test Dataloaders</strong></a></li>
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#q9-define-the-lstm-model-architecture">7.6. <strong>Q9) Define the LSTM model architecture</strong></a></li>
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#q10-define-the-loss-function-instantiate-the-model-define-the-optimizer-and-set-the-number-of-epochs-to-iterate-through">7.7. <strong>Q10) Define the loss function, instantiate the model, define the optimizer, and set the number of epochs to iterate through</strong></a></li>
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#q11-define-the-model-evaluation-function">7.8. <strong>Q11) Define the model evaluation function</strong></a></li>
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#q12-write-the-training-loop">7.9. <strong>Q12) Write the training loop</strong></a></li>
</ul>

  </nav></div>

</div></div>
              
            
          </div>
          <footer class="bd-footer-content">
            
<div class="bd-footer-content__inner container">
  
  <div class="footer-item">
    
<p class="component-author">
By Tom Beucler, Milton Gomez, Frederick Iat-Hin Tam, Jingyan Yu, Saranya Ganesh S
</p>

  </div>
  
  <div class="footer-item">
    
  <p class="copyright">
    
      © Copyright 2022.
      <br/>
    
  </p>

  </div>
  
  <div class="footer-item">
    
  </div>
  
  <div class="footer-item">
    
  </div>
  
</div>
          </footer>
        

      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="../_static/scripts/bootstrap.js?digest=e353d410970836974a52"></script>
<script src="../_static/scripts/pydata-sphinx-theme.js?digest=e353d410970836974a52"></script>

  <footer class="bd-footer">
  </footer>
  </body>
</html>